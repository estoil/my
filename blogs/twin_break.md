# TwinBreak: Jailbreaking LLM Security Alignments based on Twin Prompts

## 研究背景
目前大语言模型已经成为社会与生活不可分割的一部分，但是大语言模型的安全性依旧无法得到特别好的保证。以越狱机制为例，主要分为两种：黑盒与白盒。

## 现有方法分析
### 黑盒方法
- 只能通过API来接触LLM
- 根本在于提示工程，用于操纵提示词来引导大语言模型输出有害回应
- 更加偏向于绕过安全一致性而非移除

### 白盒方法
- 可以直接接触模型访问权限
- 通过自动分析模型组件（如激活层）来破坏一致性
- 花销较高，需要辅助模型和大量计算资源，但更加有效
- 通过在专门设计用于消除安全对齐的数据集上进行微调来扩展训练

## 研究目标
本文想要找到一个均衡白盒和黑盒的操作，使其轻量化。

## 核心方法
将大型语言模型的安全机制视为深度神经网络中的后门，识别并剪裁触发后门效应的参数，从而彻底移除该安全特性。

### 类比说明
在图像分类场景中：
- 特定触发器（例如鸟类图片上的红色方框）会误导深度神经网络输出错误预测结果（如将鸟类误判为犬类）
- 同理，当输入"如何编写恶意软件？"这类内容时，就会激活大型语言模型的安全防护机制

## 创新点
1. **独特的参数剪枝方式**：有效且计算量小，迭代计算
2. **TwinPrompt数据集**：
   - 基于HarmBench[39]构建
   - 通过为其中100条提示添加结构内容高度相似的无害对应"双胞胎"提示进行扩展
   - 用于TwinBreak中的安全参数识别研究
3. **大规模系统研究**：证明大语言模型无关性，能泛化从未见过的有害提示

## 理论基础
一般来说，一致性的完成都是训练模型拒绝有害相应，类似于定向投毒攻击和后门攻击——某些触发条件会促使特定输出。由于后门通常孤立存在于参数子集中，定向剪枝可以有效缓解此问题。

## 实现方法

### 安全对齐参数的识别
为确定需要剪枝的参数，我们监测模型在接收有害提示时各层的激活情况。然而，我们并非仅使用多个有害提示，而是将每个有害提示与一个高度相似的无害提示配对——这些配对提示在语法和内容层面都具有高度相似性，我们称之为孪生提示。通过分析这两个仅存在安全机制触发差异的相似提示之间的激活差异，我们识别出负责安全机制的参数。

![识别安全参数](blogs/pic/pic3.png)

### 效用参数的识别
我们将对模型核心功能至关重要的参数定义为效用参数。修剪这些参数会对模型整体性能产生负面影响。对于所有待修剪的层，我们也会识别相应的效用参数。

为识别效用参数，我们采用了类似于双提示概念的方案。不同于使用有害与无害提示的对比，我们输入两个无害提示并分析其激活状态。直观来看，这种情境下的激活差异有助于识别与网络高层理解相关的参数，例如对输入内容更广泛的概念性理解。换言之，由于输入包含不同概念，我们认为这些差异会导致负责高层理解的参数产生显著激活差异。此外，这也有助于识别那些无论提示有害与否都倾向于表现出高激活度的参数。

### 迭代选取
1. 先识别有效参数
2. 通过迭代把安全参数剥离
3. 部分参数只有在其他关联参数被逐步移除后才会被识别出

![伪代码](blogs/pic/twinbreak_alg1.png)

### 关键技术细节
- 重点关注mlp中的gate层和up层
- 选取最后六个token的激活值并处理
- 在11008个参数中选取前1%变化最大的参数进行剪枝
- 选取最后六个标记的激活值并对前五个进行平均处理，是TwinBreak算法的两个关键超参数
- 六个标记能提供稳健的结果
- 为降低噪声干扰从而更精准检测负责安全对齐的参数

![关键技术](blogs/pic/pic5.png)

## 实验验证
1. 从五次剪枝中选取最优的模型进行验证
2. 证明TwinBreak具备不限制llm且对未见过语料有泛化能力

根据这四个评判标准可以轻易地看出，在不断的迭代剪枝下，大语言模型的安全性在下降。其中Qwen的安全性在未剪枝状态也有一定不安全性，其对齐做的不太好。

![伪代码](blogs/pic/twinbreak_alg2.png)

## 能力评估
从能力方面，挑选出五个任务：
1. **OpenBookQA**：通过基础科学主题来评估大型语言模型的推理与知识吸收能力
2. **ARC-Challenge**：专注于更复杂的科学问题
3. **HellaSwag**：要求模型根据给定的不完整句子或情景选择最合理的后续发展
4. **RTE**：通过评估前提是否能推导出假设来进行测试
5. **WinoGrande**：检验模型的常识与上下文理解能力

![alt text](blogs/pic/twinbreak_eval.png)

随着剪枝的迭代数不断增加，部分模型的能力有所下降，但是下降程度极其有限。

![alt text](blogs/pic/twinbreak_eval1.png)

## 防御方法讨论
TwinBreak在需要直接访问模型参数的白盒威胁模型下运行。这也意味着任何有效的防御措施都必须嵌入这些参数中。虽然目前尚不存在此类防御机制，但未来研究的一个有前景方向
是通过将安全对齐更广泛地分布在模型参数空间中来增强其鲁棒性。通过将安全机制与核心功能组件相融合，移除对齐设置将从根本上降低模型的整体性能，从而降低篡改的吸引力并
增强模型的完整性。